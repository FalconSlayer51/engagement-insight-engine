{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\projects\\turtil_internship\\engagement-insight-engine\\model\\ml_model\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.6973 - loss: 0.6292 - precision: 0.5528 - recall: 0.7605 - val_accuracy: 0.6444 - val_loss: 0.5508 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9077 - loss: 0.2901 - precision: 0.8533 - recall: 0.8923 - val_accuracy: 0.6444 - val_loss: 0.5631 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9289 - loss: 0.2613 - precision: 0.9090 - recall: 0.8902 - val_accuracy: 0.6444 - val_loss: 0.5195 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9228 - loss: 0.2601 - precision: 0.9078 - recall: 0.8693 - val_accuracy: 0.8119 - val_loss: 0.3746 - val_precision: 0.9379 - val_recall: 0.5044\n",
      "Epoch 5/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9326 - loss: 0.2531 - precision: 0.9224 - recall: 0.8842 - val_accuracy: 0.9237 - val_loss: 0.2637 - val_precision: 0.9408 - val_recall: 0.8383\n",
      "Epoch 6/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9366 - loss: 0.2397 - precision: 0.9122 - recall: 0.9012 - val_accuracy: 0.9119 - val_loss: 0.2596 - val_precision: 0.9403 - val_recall: 0.8032\n",
      "Epoch 7/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9339 - loss: 0.2446 - precision: 0.9251 - recall: 0.8873 - val_accuracy: 0.9337 - val_loss: 0.2401 - val_precision: 0.9410 - val_recall: 0.8682\n",
      "Epoch 8/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9357 - loss: 0.2499 - precision: 0.9164 - recall: 0.8973 - val_accuracy: 0.9419 - val_loss: 0.2303 - val_precision: 0.9391 - val_recall: 0.8946\n",
      "Epoch 9/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9325 - loss: 0.2497 - precision: 0.9222 - recall: 0.8818 - val_accuracy: 0.9337 - val_loss: 0.2325 - val_precision: 0.9410 - val_recall: 0.8682\n",
      "Epoch 10/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9362 - loss: 0.2421 - precision: 0.9344 - recall: 0.8847 - val_accuracy: 0.9419 - val_loss: 0.2293 - val_precision: 0.9391 - val_recall: 0.8946\n",
      "Epoch 11/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9445 - loss: 0.2174 - precision: 0.9376 - recall: 0.8983 - val_accuracy: 0.9337 - val_loss: 0.2342 - val_precision: 0.9410 - val_recall: 0.8682\n",
      "Epoch 12/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9403 - loss: 0.2354 - precision: 0.9320 - recall: 0.8956 - val_accuracy: 0.9513 - val_loss: 0.2235 - val_precision: 0.9392 - val_recall: 0.9227\n",
      "Epoch 13/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9422 - loss: 0.2284 - precision: 0.9365 - recall: 0.8999 - val_accuracy: 0.9513 - val_loss: 0.2249 - val_precision: 0.9392 - val_recall: 0.9227\n",
      "Epoch 14/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9405 - loss: 0.2353 - precision: 0.9301 - recall: 0.8967 - val_accuracy: 0.9419 - val_loss: 0.2237 - val_precision: 0.9391 - val_recall: 0.8946\n",
      "Epoch 15/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9417 - loss: 0.2324 - precision: 0.9324 - recall: 0.9006 - val_accuracy: 0.9444 - val_loss: 0.2246 - val_precision: 0.9196 - val_recall: 0.9244\n",
      "Epoch 16/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9415 - loss: 0.2318 - precision: 0.9272 - recall: 0.9029 - val_accuracy: 0.9444 - val_loss: 0.2223 - val_precision: 0.9196 - val_recall: 0.9244\n",
      "Epoch 17/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9435 - loss: 0.2232 - precision: 0.9461 - recall: 0.8967 - val_accuracy: 0.9419 - val_loss: 0.2207 - val_precision: 0.9391 - val_recall: 0.8946\n",
      "Epoch 18/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9365 - loss: 0.2319 - precision: 0.9293 - recall: 0.8850 - val_accuracy: 0.9444 - val_loss: 0.2201 - val_precision: 0.9196 - val_recall: 0.9244\n",
      "Epoch 19/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9423 - loss: 0.2220 - precision: 0.9377 - recall: 0.8968 - val_accuracy: 0.9513 - val_loss: 0.2154 - val_precision: 0.9392 - val_recall: 0.9227\n",
      "Epoch 20/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9445 - loss: 0.2230 - precision: 0.9374 - recall: 0.9038 - val_accuracy: 0.9444 - val_loss: 0.2159 - val_precision: 0.9196 - val_recall: 0.9244\n",
      "Epoch 21/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9439 - loss: 0.2227 - precision: 0.9377 - recall: 0.8983 - val_accuracy: 0.9419 - val_loss: 0.2134 - val_precision: 0.9391 - val_recall: 0.8946\n",
      "Epoch 22/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9434 - loss: 0.2262 - precision: 0.9425 - recall: 0.8976 - val_accuracy: 0.9513 - val_loss: 0.2134 - val_precision: 0.9392 - val_recall: 0.9227\n",
      "Epoch 23/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9499 - loss: 0.2103 - precision: 0.9470 - recall: 0.9089 - val_accuracy: 0.9419 - val_loss: 0.2139 - val_precision: 0.9391 - val_recall: 0.8946\n",
      "Epoch 24/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9406 - loss: 0.2225 - precision: 0.9419 - recall: 0.8844 - val_accuracy: 0.9419 - val_loss: 0.2134 - val_precision: 0.9391 - val_recall: 0.8946\n",
      "Epoch 25/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9432 - loss: 0.2172 - precision: 0.9487 - recall: 0.8923 - val_accuracy: 0.9444 - val_loss: 0.2155 - val_precision: 0.9196 - val_recall: 0.9244\n",
      "Epoch 26/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9494 - loss: 0.2003 - precision: 0.9448 - recall: 0.9081 - val_accuracy: 0.9513 - val_loss: 0.2099 - val_precision: 0.9392 - val_recall: 0.9227\n",
      "Epoch 27/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9458 - loss: 0.2194 - precision: 0.9413 - recall: 0.9052 - val_accuracy: 0.9513 - val_loss: 0.2084 - val_precision: 0.9392 - val_recall: 0.9227\n",
      "Epoch 28/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9411 - loss: 0.2293 - precision: 0.9331 - recall: 0.9000 - val_accuracy: 0.9513 - val_loss: 0.2079 - val_precision: 0.9392 - val_recall: 0.9227\n",
      "Epoch 29/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9414 - loss: 0.2362 - precision: 0.9389 - recall: 0.8953 - val_accuracy: 0.9513 - val_loss: 0.2113 - val_precision: 0.9392 - val_recall: 0.9227\n",
      "Epoch 30/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9489 - loss: 0.2157 - precision: 0.9450 - recall: 0.9090 - val_accuracy: 0.9513 - val_loss: 0.2075 - val_precision: 0.9392 - val_recall: 0.9227\n",
      "Epoch 31/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9507 - loss: 0.2084 - precision: 0.9460 - recall: 0.9145 - val_accuracy: 0.9513 - val_loss: 0.2087 - val_precision: 0.9392 - val_recall: 0.9227\n",
      "Epoch 32/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9430 - loss: 0.2216 - precision: 0.9399 - recall: 0.8949 - val_accuracy: 0.9513 - val_loss: 0.2075 - val_precision: 0.9392 - val_recall: 0.9227\n",
      "Epoch 33/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9444 - loss: 0.2141 - precision: 0.9425 - recall: 0.8984 - val_accuracy: 0.9513 - val_loss: 0.2087 - val_precision: 0.9392 - val_recall: 0.9227\n",
      "Epoch 34/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9388 - loss: 0.2352 - precision: 0.9285 - recall: 0.8954 - val_accuracy: 0.9419 - val_loss: 0.2083 - val_precision: 0.9391 - val_recall: 0.8946\n",
      "Epoch 35/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9474 - loss: 0.2064 - precision: 0.9459 - recall: 0.9067 - val_accuracy: 0.9419 - val_loss: 0.2161 - val_precision: 0.9391 - val_recall: 0.8946\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      1290\n",
      "           1       0.95      0.92      0.93       710\n",
      "\n",
      "    accuracy                           0.95      2000\n",
      "   macro avg       0.95      0.95      0.95      2000\n",
      "weighted avg       0.95      0.95      0.95      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"new_datasets/balanced_resume_dataset_realistic_noisy.csv\")  # Replace with actual path\n",
    "\n",
    "# Feature & target separation\n",
    "X = df[['resume_uploaded', 'batch_resume_uploaded_pct']]\n",
    "y = df['should_nudge_resume']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(2,)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    ")\n",
    "\n",
    "# Early stopping\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "should_nudge_resume\n",
       "0    6450\n",
       "1    3550\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['should_nudge_resume'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Metrics on Test Dataset:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1281\n",
      "           1       0.96      0.92      0.94       719\n",
      "\n",
      "    accuracy                           0.96      2000\n",
      "   macro avg       0.96      0.95      0.95      2000\n",
      "weighted avg       0.96      0.96      0.96      2000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1255   26]\n",
      " [  57  662]]\n",
      "\n",
      "Accuracy Score: 0.9585\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "test_df = pd.read_csv('new_datasets/balanced_test_resume_dataset_realistic_noisy.csv')\n",
    "\n",
    "X_test_new = test_df[['resume_uploaded', 'batch_resume_uploaded_pct']]\n",
    "y_test_new = test_df['should_nudge_resume']\n",
    "\n",
    "y_pred_new = (model.predict(X_test_new) > 0.5).astype(int)\n",
    "\n",
    "# Print metrics\n",
    "print(\"\\nMetrics on Test Dataset:\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_new, y_pred_new))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_new, y_pred_new))\n",
    "\n",
    "print(\"\\nAccuracy Score:\", accuracy_score(y_test_new, y_pred_new))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('models/model_resume.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Results:\n",
      "\n",
      "Original Test Set Metrics:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      1290\n",
      "           1       0.95      0.92      0.93       710\n",
      "\n",
      "    accuracy                           0.95      2000\n",
      "   macro avg       0.95      0.95      0.95      2000\n",
      "weighted avg       0.95      0.95      0.95      2000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1252   38]\n",
      " [  55  655]]\n",
      "\n",
      "Accuracy Score: 0.9535\n",
      "\n",
      "New Test Set Metrics:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1281\n",
      "           1       0.96      0.92      0.94       719\n",
      "\n",
      "    accuracy                           0.96      2000\n",
      "   macro avg       0.96      0.95      0.95      2000\n",
      "weighted avg       0.96      0.96      0.96      2000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1255   26]\n",
      " [  57  662]]\n",
      "\n",
      "Accuracy Score: 0.9585\n"
     ]
    }
   ],
   "source": [
    "# Create and train Random Forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the model\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model using the same training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on both test sets\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "rf_pred_new = rf_model.predict(X_test_new)\n",
    "\n",
    "print(\"\\nRandom Forest Results:\")\n",
    "print(\"\\nOriginal Test Set Metrics:\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, rf_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, rf_pred))\n",
    "print(\"\\nAccuracy Score:\", accuracy_score(y_test, rf_pred))\n",
    "\n",
    "print(\"\\nNew Test Set Metrics:\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_new, rf_pred_new))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_new, rf_pred_new))\n",
    "print(\"\\nAccuracy Score:\", accuracy_score(y_test_new, rf_pred_new))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/random_forest_resume.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "dump(rf_model, 'models/random_forest_resume.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
