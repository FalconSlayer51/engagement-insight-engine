{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\projects\\turtil_internship\\engagement-insight-engine\\model\\ml_model\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.5583 - loss: 0.8547 - precision_1: 0.6876 - recall_1: 0.6334 - val_accuracy: 0.6469 - val_loss: 0.6488 - val_precision_1: 0.7026 - val_recall_1: 0.8393\n",
      "Epoch 2/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7239 - loss: 0.5723 - precision_1: 0.7778 - recall_1: 0.8307 - val_accuracy: 0.6237 - val_loss: 0.6513 - val_precision_1: 0.7211 - val_recall_1: 0.7342\n",
      "Epoch 3/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8202 - loss: 0.4120 - precision_1: 0.8438 - recall_1: 0.9055 - val_accuracy: 0.7113 - val_loss: 0.6113 - val_precision_1: 0.7035 - val_recall_1: 0.9991\n",
      "Epoch 4/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8390 - loss: 0.3583 - precision_1: 0.8612 - recall_1: 0.9151 - val_accuracy: 0.7156 - val_loss: 0.5703 - val_precision_1: 0.7481 - val_recall_1: 0.8813\n",
      "Epoch 5/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8296 - loss: 0.3647 - precision_1: 0.8471 - recall_1: 0.9138 - val_accuracy: 0.7163 - val_loss: 0.4810 - val_precision_1: 0.7072 - val_recall_1: 0.9991\n",
      "Epoch 6/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8503 - loss: 0.3267 - precision_1: 0.8555 - recall_1: 0.9378 - val_accuracy: 0.6844 - val_loss: 0.7891 - val_precision_1: 0.6844 - val_recall_1: 1.0000\n",
      "Epoch 7/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8520 - loss: 0.3228 - precision_1: 0.8593 - recall_1: 0.9331 - val_accuracy: 0.6969 - val_loss: 0.8490 - val_precision_1: 0.6930 - val_recall_1: 1.0000\n",
      "Epoch 8/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8636 - loss: 0.2985 - precision_1: 0.8711 - recall_1: 0.9376 - val_accuracy: 0.9094 - val_loss: 0.2429 - val_precision_1: 0.9907 - val_recall_1: 0.8758\n",
      "Epoch 9/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8565 - loss: 0.3117 - precision_1: 0.8623 - recall_1: 0.9408 - val_accuracy: 0.9613 - val_loss: 0.1730 - val_precision_1: 0.9551 - val_recall_1: 0.9900\n",
      "Epoch 10/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8545 - loss: 0.2996 - precision_1: 0.8481 - recall_1: 0.9543 - val_accuracy: 0.8637 - val_loss: 0.2852 - val_precision_1: 0.8360 - val_recall_1: 0.9963\n",
      "Epoch 11/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8465 - loss: 0.3153 - precision_1: 0.8520 - recall_1: 0.9386 - val_accuracy: 0.8938 - val_loss: 0.2154 - val_precision_1: 0.8685 - val_recall_1: 0.9954\n",
      "Epoch 12/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8559 - loss: 0.3261 - precision_1: 0.8550 - recall_1: 0.9504 - val_accuracy: 0.8375 - val_loss: 0.3910 - val_precision_1: 0.8095 - val_recall_1: 0.9973\n",
      "Epoch 13/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8968 - loss: 0.2459 - precision_1: 0.9005 - recall_1: 0.9512 - val_accuracy: 0.9294 - val_loss: 0.1836 - val_precision_1: 0.9119 - val_recall_1: 0.9927\n",
      "Epoch 14/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9001 - loss: 0.2523 - precision_1: 0.9051 - recall_1: 0.9522 - val_accuracy: 0.9563 - val_loss: 0.1445 - val_precision_1: 0.9646 - val_recall_1: 0.9717\n",
      "Epoch 15/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9087 - loss: 0.2272 - precision_1: 0.9090 - recall_1: 0.9620 - val_accuracy: 0.8775 - val_loss: 0.2941 - val_precision_1: 0.8504 - val_recall_1: 0.9963\n",
      "Epoch 16/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9148 - loss: 0.2146 - precision_1: 0.9172 - recall_1: 0.9611 - val_accuracy: 0.9406 - val_loss: 0.1580 - val_precision_1: 0.9237 - val_recall_1: 0.9954\n",
      "Epoch 17/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9096 - loss: 0.2291 - precision_1: 0.9144 - recall_1: 0.9567 - val_accuracy: 0.9244 - val_loss: 0.1969 - val_precision_1: 0.9860 - val_recall_1: 0.9023\n",
      "Epoch 18/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9089 - loss: 0.2324 - precision_1: 0.9137 - recall_1: 0.9578 - val_accuracy: 0.9650 - val_loss: 0.1354 - val_precision_1: 0.9770 - val_recall_1: 0.9717\n",
      "Epoch 19/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9091 - loss: 0.2233 - precision_1: 0.9174 - recall_1: 0.9524 - val_accuracy: 0.8606 - val_loss: 0.3501 - val_precision_1: 0.8323 - val_recall_1: 0.9973\n",
      "Epoch 20/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9037 - loss: 0.2204 - precision_1: 0.9015 - recall_1: 0.9606 - val_accuracy: 0.9319 - val_loss: 0.1837 - val_precision_1: 0.9852 - val_recall_1: 0.9142\n",
      "Epoch 21/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9156 - loss: 0.2131 - precision_1: 0.9107 - recall_1: 0.9697 - val_accuracy: 0.9056 - val_loss: 0.2182 - val_precision_1: 0.8813 - val_recall_1: 0.9963\n",
      "Epoch 22/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9272 - loss: 0.2009 - precision_1: 0.9227 - recall_1: 0.9739 - val_accuracy: 0.8750 - val_loss: 0.3159 - val_precision_1: 0.9901 - val_recall_1: 0.8256\n",
      "Epoch 23/100\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9118 - loss: 0.2232 - precision_1: 0.9137 - recall_1: 0.9608 - val_accuracy: 0.9337 - val_loss: 0.1795 - val_precision_1: 0.9911 - val_recall_1: 0.9114\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94       642\n",
      "           1       0.98      0.97      0.97      1358\n",
      "\n",
      "    accuracy                           0.96      2000\n",
      "   macro avg       0.96      0.96      0.96      2000\n",
      "weighted avg       0.96      0.96      0.96      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"train_dataset/event_dataset.csv\")  # Replace with actual path\n",
    "\n",
    "# Feature & target separation\n",
    "X = df[['karma', 'event_fomo_score']]\n",
    "y = df['should_nudge_event']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Define model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(2,)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    ")\n",
    "\n",
    "# Early stopping\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "should_nudge_event\n",
       "1    6791\n",
       "0    3209\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts('should_nudge_event')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Metrics on Test Dataset:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84      1207\n",
      "           1       0.80      0.65      0.72       793\n",
      "\n",
      "    accuracy                           0.80      2000\n",
      "   macro avg       0.80      0.77      0.78      2000\n",
      "weighted avg       0.80      0.80      0.79      2000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1079  128]\n",
      " [ 274  519]]\n",
      "\n",
      "Accuracy Score: 0.799\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "test_df = pd.read_csv('test_dataset/test_event_dataset.csv')\n",
    "\n",
    "X_test_new = test_df[['karma', 'event_fomo_score']]\n",
    "y_test_new = test_df['should_nudge_event']\n",
    "\n",
    "y_pred_new = (model.predict(X_test_new) > 0.5).astype(int)\n",
    "\n",
    "# Print metrics\n",
    "print(\"\\nMetrics on Test Dataset:\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_new, y_pred_new))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_new, y_pred_new))\n",
    "\n",
    "print(\"\\nAccuracy Score:\", accuracy_score(y_test_new, y_pred_new))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('models/model_event.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Results on Original Test Set:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       642\n",
      "           1       0.97      0.98      0.97      1358\n",
      "\n",
      "    accuracy                           0.96      2000\n",
      "   macro avg       0.96      0.96      0.96      2000\n",
      "weighted avg       0.96      0.96      0.96      2000\n",
      "\n",
      "\n",
      "Random Forest Results on New Test Dataset:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.85      1207\n",
      "           1       0.82      0.66      0.73       793\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.81      0.78      0.79      2000\n",
      "weighted avg       0.81      0.81      0.80      2000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1089  118]\n",
      " [ 272  521]]\n",
      "\n",
      "Accuracy Score: 0.805\n"
     ]
    }
   ],
   "source": [
    "# Create and train Random Forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Initialize the model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on original test set\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "print(\"\\nRandom Forest Results on Original Test Set:\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, rf_pred))\n",
    "\n",
    "# Predict on new test dataset\n",
    "rf_pred_new = rf_model.predict(X_test_new)\n",
    "\n",
    "print(\"\\nRandom Forest Results on New Test Dataset:\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_new, rf_pred_new))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_new, rf_pred_new))\n",
    "\n",
    "print(\"\\nAccuracy Score:\", accuracy_score(y_test_new, rf_pred_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/rf_model_event.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save Random Forest model using joblib\n",
    "from joblib import dump\n",
    "dump(rf_model, 'models/rf_model_event.joblib')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
